{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a Spark MLlib model to IBM Watson Machine Learning\n",
    "\n",
    "Importing a model into Watson Machine Learning means to store a trained model in your Watson Machine Learning repository and then deploy the stored model.  This notebook demonstrates importing an in-memory, Spark MLlib PipelineModel object.\n",
    "\n",
    "See also: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-import-spark-mllib.html\" target=\"_blank\" rel=\"noopener noreferrer\">Importing a Spark MLlib model</a>\n",
    "\n",
    "This notebook runs on Spark Python 3.5.\n",
    "\n",
    "\n",
    "### Notebook sections\n",
    "\n",
    "[Setup](#setup)\n",
    "\n",
    "1. [Load training data](#loadata)\n",
    "2. [Build model](#buildmodel)\n",
    "3. [Train and evaluate model](#trainmodel)\n",
    "4. [Store and deploy model](#storedeploymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"setup\"></a> Set up\n",
    "- Install packages\n",
    "- Import libraries\n",
    "- Instaiate a Watson Machine Learning client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget # needed to download sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install watson_machine_learning_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste your Watson Machine Learning credentials in the following cell.\n",
    "\n",
    "See: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-get-wml-credentials.html\" target=\"_blank\" rel=\"noopener noreferrer\">Looking up credentials</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Watson Machine Learning client instance\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "wml_credentials = {\n",
    "    \"instance_id\" : \"\",\n",
    "    \"password\"    : \"\",\n",
    "    \"url\"         : \"\",\n",
    "    \"username\"    : \"\"\n",
    "}\n",
    "client = WatsonMachineLearningAPIClient( wml_credentials )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"loaddata\"></a> 1. Load and prepare sample training data\n",
    "\n",
    "**About the sample model**\n",
    "\n",
    "The sample model built here is a logistic regression model for predicting whether or not a customer will purchase a tent from a fictional outdoor equipment store, based on the customer charateristics.\n",
    "\n",
    "The data used to train the model is the \"GoSales.csv\" training data in the IBM Watson Studio community: <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/aa07a773f71cf1172a349f33e2028e4e\" target=\"_blank\" rel=\"noopener noreferrer\">GoSales sample data</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoSales.csv\n"
     ]
    }
   ],
   "source": [
    "# Download sample training data to notebook working directory\n",
    "import wget\n",
    "training_data_url = 'https://dataplatform.cloud.ibm.com/data/exchange-api/v1/entries/aa07a773f71cf1172a349f33e2028e4e/data?accessKey=e98b7315f84e5448aa94c633ca66ea83'\n",
    "filename = wget.download( training_data_url )\n",
    "print( filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      " |-- IS_TENT: boolean (nullable = true)\n",
      " |-- PRODUCT_LINE: string (nullable = true)\n",
      " |-- PURCHASE_AMOUNT: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read sample data into a Spark DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load( filename )\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      " |-- IS_TENT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns of interest\n",
    "from pyspark.sql.types import IntegerType\n",
    "training_data = df.select( \"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", df.IS_TENT.cast( IntegerType() ) )\n",
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"buildmodel\"></a> 2. Build a PipelineModel object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexers for string columns\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer_GENDER         = StringIndexer( inputCol=\"GENDER\",         outputCol=\"GENDER_index\"         )\n",
    "indexer_MARITAL_STATUS = StringIndexer( inputCol=\"MARITAL_STATUS\", outputCol=\"MARITAL_STATUS_index\" )\n",
    "indexer_PROFESSION     = StringIndexer( inputCol=\"PROFESSION\",     outputCol=\"PROFESSION_index\"     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assembler that generates the feature vector column\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "feature_vector_assembler = VectorAssembler( inputCols=[ \"GENDER_index\", \"AGE\", \"MARITAL_STATUS_index\", \"PROFESSION_index\" ],  outputCol=\"features\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression( featuresCol='features', labelCol='IS_TENT' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PipelineModel\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline( stages=[ indexer_GENDER, indexer_MARITAL_STATUS, indexer_PROFESSION, feature_vector_assembler, lr ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"trainmodel\"></a> 3. Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 45186\n",
      "Test count: 15066\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into a training set and a test set\n",
    "train, test = training_data.randomSplit( [ 0.75, 0.25 ], seed = 2019 )\n",
    "print( \"Train count: \" + str( train.count() ) )\n",
    "print( \"Test count: \"  + str( test.count()  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the PipelineModel\n",
    "pipeline_model = pipeline.fit( train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 78%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "predictions = pipeline_model.transform( test )\n",
    "correct_false = predictions.filter( \"IS_TENT == 0 AND prediction == 0.0\" )\n",
    "correct_true = predictions.filter( \"IS_TENT == 1 AND prediction != 0.0\" )\n",
    "print( \"Success rate: \" + str( round( 100 * ( ( correct_false.count() + correct_true.count() ) / predictions.count() ) ) ) + \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"storedeploymodel\"></a> 4. Store and deploy the model in Watson Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the PipelineModel in the Watson Machine Learning repository\n",
    "model_details = client.repository.store_model( pipeline_model, 'Spark MLlib model', training_data=train, pipeline=pipeline )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the stored model as an online web service deployment\n",
    "model_id = model_details[\"metadata\"][\"guid\"]\n",
    "deployment_details = client.deployments.create( artifact_uid=model_id, name=\"Spark MLlib model deployment\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['GENDER',\n",
       "  'AGE',\n",
       "  'MARITAL_STATUS',\n",
       "  'PROFESSION',\n",
       "  'GENDER_index',\n",
       "  'MARITAL_STATUS_index',\n",
       "  'PROFESSION_index',\n",
       "  'features',\n",
       "  'rawPrediction',\n",
       "  'probability',\n",
       "  'prediction'],\n",
       " 'values': [['M',\n",
       "   27,\n",
       "   'Single',\n",
       "   'Professional',\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   [0.0, 27.0, 1.0, 1.0],\n",
       "   [0.16773330636208073, -0.16773330636208073],\n",
       "   [0.541835288108435, 0.458164711891565],\n",
       "   0.0]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the deployment\n",
    "model_endpoint_url = client.deployments.get_scoring_url( deployment_details )\n",
    "payload = { \"fields\" : [ \"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\" ], \"values\" : [ [ \"M\", 27, \"Single\", \"Professional\" ] ] }\n",
    "client.deployments.score( model_endpoint_url, payload )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------------+------------+------------+--------------------+----------------+------------------+--------------------+--------------------+----------+\n",
      "|GENDER|AGE|MARITAL_STATUS|  PROFESSION|GENDER_index|MARITAL_STATUS_index|PROFESSION_index|          features|       rawPrediction|         probability|prediction|\n",
      "+------+---+--------------+------------+------------+--------------------+----------------+------------------+--------------------+--------------------+----------+\n",
      "|     M| 27|        Single|Professional|         0.0|                 1.0|             1.0|[0.0,27.0,1.0,1.0]|[0.16773330636208...|[0.54183528810843...|       0.0|\n",
      "+------+---+--------------+------------+------------+--------------------+----------------+------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the model locally gets the same results\n",
    "test_df = spark.createDataFrame( [ ( \"M\", 27, \"Single\", \"Professional\" ) ], [ \"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\" ] )\n",
    "pipeline_model.transform( test_df ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, you imported an in-memory, Spark MLlib PipelineModel into Watson Machine Learning using the Watson Machine Learning Python client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"authors\"></a>Authors\n",
    "\n",
    "**Sarah Packowski** is a member of the IBM Watson Studio Content Design team in Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2019. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
